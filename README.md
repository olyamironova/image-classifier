# image-classifier
Проект решает задачу многоклассовой классификации изображений картин по жанру живописи (барокко, средневековье, современное искусство)

Для сбора датасета написала два парсера:
- wga-parser.py для парсинга картин периода XVI-XIX веков (барокко, средневековье) с сайта https://www.wga.hu/ 
- modern-image-parser.py для парсинга сайта https://www.tate.org.uk с картинами, относящимися к современному икусству (XX-XXI века)  
В полученном датасете в каждом из трех классов было по 1200 изображений.

Реализовала модель архитектуры CNN в качестве baseline-решения (Conv2d -> BatchNorm2d -> SiLU -> MaxPool2d), в качестве целевого решения подняла заранее предобученную модель ResNet18 из torchvision.models. 

Сделала стратификационное разбиение исходного датасета на train/val/test для сохранения баланса классов. На этапе предобработки, чтобы искусственно разнообразить датасет, в качестве аугментаций изображений из обучающей выборки применяла трансформации RandomResizedCrop, RandomHorizontalFlip, ColorJitter из библиотеки torchvision.transforms для повышения обобщающей способности модели. Над тестовой выборкой применяла детерминированные преобразования Resize, CenterCrop. Модели CNN и ResNet18 обучались на одинаковом датасете, все тензоры из датасета дополнительно нормализовала по mean и std значениям, полученным в ходе обучения ResNet18 на датасете ImageNet. Для ResNet18 это было необходимо, чтобы модель максимально эффективно решала задачу классификации на тех весах, которые рассчитались в процессе обучения, а для CNN решила использовать с такими же значениями, чтобы валидно сравнивать CNN и ResNet18. 

Обе модели обучала с применением фреймворка PyTorch, в качестве функции потерь использовала кросс-энтропию, для CNN использовала AdamW как метод оптимизации, для ResNet18 взяла Adam, применяла регуляризацию (Weight Decay). Следила, чтобы модели не переобучались: в конце каждой эпохи выводила метрики обучения и валидации (loss и accuracy на train и val сплитах). В качестве метрик во время обучения использовала Accuracy и F1-score, после обучения тестировала модель по отложенной выборке test и выводила classification_report (accuracy, precision, recall, macro f1-score). 

Для обучения ResNet18 модели реализовала Transfer Learning:
• Загрузка весов ImageNet
• Заморозка (freezing) backbone и обучение только "головы" (FC-слоев)
• Разморозка (unfreezing) и fine-tuning всей сети с разными learning rate для backbone и головы (использование групп параметров в оптимизаторе)
• Использование CosineAnnealingLR scheduler'a
На обучении ResNet18 экспериментировала с подбором метода оптимизации (пробовала Adam и SGD) и сравнивала метрики Accuracy и Loss на одинаковых эпохах (на Adam было лучше), также в процессе всего обучения логгировала метрики обучения и валидации с использованием TensorBoard и с помощью обычного вывода в консоль (print).

Для визуализации эмбеддингов использовала эмбеддинги из предпоследнего линейного слоя модели, полученные эмбеддинги отобразила в 2d-пространстве с помощью t-SNE и UMAP, в качестве метрики явно использовала косинусовое сходство. 